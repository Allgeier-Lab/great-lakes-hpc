---
title: "Great lakes"
author:
  - Katrina S. Munsterman
  - Maximilian H.K. Hesselbarth
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

## Get accsess to HPC

First you need to get access to the HPC. For this, use [this link](https://teamdynamix.umich.edu/TDClient/30/Portal/Requests/ServiceDet?ID=42) and complete the form to enable your U-Mich account to login to the HPC. 

Also, talk to Jake about which funding to use. He can additionally send an e-mail to the support team to add your account to the [U-M Research Computing Package](https://arc.umich.edu/umrcp/) which allows to use a certain amount of free-of-cost minutes. Maybe you are even eligible for your own free-of-costs minutes.

Once you have an account, use your Terminal.app to login to the HPC. For this use the following line. When asked to type your password, the cursor will not move! Make sure to have your 2-factor authentication ready (DuoMobile). In case you are not on Campus, you need to use a [VPN](https://its.umich.edu/enterprise/wifi-networks/vpn/getting-started).

```{bash ssh}
ssh <username>@greatlakes.arc-ts.umich.edu
```

## Setup your HPC account

If you use the HPC for the first time, you need to setup a few files and settings to make future uses easier. Luckiy, you have to do these steps only once!

First, check out your `.bash_profile` file by typing `nano .bash_profile`. This will either open the file (using a text editor) or create the file if it doesnt exit yet. Copy the following text into the file. To exit the text editor, press `control + x` and agree to saving the file by following the prompts.

```{bash profile
# .bash_profile

# load aliases
if [ -f ~/.bash_aliases ]; then
    . ~/.bash_aliases
fi

# load modules
if [ -f ~/.bash_modules ]; then
    . ~/.bash_modules
fi

## User specific environment and startup programs
# PATH=$PATH:$HOME/.local/bin:$HOME/bin
# export PATH
```

Next, we need to create `.bash_aliases` by again typing `nano .bash_aliases`. Copy the following text into the file and exit/save it as before. This file will create some easy accessible shortcuts/commands. You can always extend this list.  

```{bash aliases}
## General HPC/Account information
alias partitions_info='sinfo --sum'
alias jobs_standard='squeue --partition=standard --format="%.12i %.18j %.8u %.6a %.9P %.10l %.10M %.5D %.4C %.7m %16R %.8T"'
alias jobs_largemem='squeue --partition=largemem --format="%.12i %.18j %.8u %.6a  %.9P %.10l %.10M %.5D %.4C %.7m %16R %.8T"'
alias account_info='sacctmgr show assoc user=$USER format=cluster,account,QOS,user,MaxSubmit,MaxJobs,GrpTRES'

alias fairshare='sshare -U $USER'

## Information submitted jobs
alias jobs_own='squeue -u $USER --format="%.21i %.18j %.8u %.7a %.9P %.10l %.10M %.5D %.4C %.7m %16R %.8T"'
alias jobs_run='squeue -u $USER --states=RUNNING --format="%.21i %.18j %.8u %.7a %.9P %.10l %.10M %.5D %.4C %.7m %16R %.8T"'
alias jobs_pen='squeue -u $USER --states=PENDING --format="%.21i %.18j %.8u %.7a %.9P %.10l %.10M %.5D %.4C %.7m %16R %.8T"'
alias jobs_n='squeue -u $USER --states=RUNNING --noheader | wc -l'
alias jobs_kill='scancel -u $USER'
alias jobs_info='sacct -u $USER --units=G --format=JobID,JobName,Account,Partition,Timelimit,Elapsed,AllocNodes,AllocCPU,ReqMem,MaxRSS,State'

## Delete file types
alias rm_logs='rm -rf *.log'
alias rm_rds='rm -rf *.rds'
alias rm_rslurm='rm -rf _rslurm_*'
```
Last, we need to create `.bash_modules`. Again, type `nano .bash_modules` and copy the following text before exit/saving the file. This makes sure, each time you use the HPC some pre-installed software libraries are available (such as e.g. `R`). If you dont use any spatial packages you could delete the lines loading `gdal`, `proj`, and `geos`.

```{bash modules}
## Load modules

module load gcc/8.2.0
module load R/4.1.0

module load gdal
module load proj
module load geos
```

## Install R packages on the HPC

You need to install all `R` packages that you want to use on the HPC once. For this, login to the HPC and start a `R` session in the terminal by typing `R`. Now, simply run `install.packages(c("package_name_1, package_name_2"))` to install all packages you need. The first time you run the command, it might prompt you a question if you want to create your own libraries folder. Say yes to this. Also, you need to select a CRAN mirror. Just pick any number during the corresponding prompt message.

You need to re-do this step each time you want to run some code with a new package you have not installed previously.

Once you have installed all packages, exit the `R` session by typing `Q()` (...and do not save your workspace image by pressing `n`...).

Thats so far everything we need to setup on the HPC! The next steps are on your local disk again.

## rslurm template

```{bash rslurm_template}
#!/bin/sh
#SBATCH --account={{ account | jeallg1 }} # account
#SBATCH --job-name={{ job_name }} # job name
#SBATCH --array=1-{{ n_jobs }} # number of processes
#SBATCH --partition={{ partition | standard }} # name of queue
#SBATCH --nodes={{ nodes | 1 }} # if one load, is out on one node
#SBATCH --cpus-per-task={{ n_cpu | 1 }} # set cores per task
#SBATCH --mem-per-cpu={{ mem_cpu | 1024 }} # memory per cpu 
#SBATCH --time={{ walltime | 12:00:00 }} # walltime in hh:mm:ss
#SBATCH --output={{ log_file | /dev/null }}
#SBATCH --error={{ log_file | /dev/null }}

module load gcc/8.2.0
module load R/4.0.2

ulimit -v $(( 1024 * {{ mem_cpu | 1024 }} ))
CMQ_AUTH={{ auth }} R --no-save --no-restore -e 'clustermq:::worker("{{ master }}")'
```

## Code example
